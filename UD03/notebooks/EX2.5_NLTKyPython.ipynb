{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afcea688-88b6-46ea-a926-e12770c2aaa5",
   "metadata": {},
   "source": [
    "# Ejercicios UD03_02.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f1713",
   "metadata": {},
   "source": [
    "## Uso de NLTK y Python\n",
    "\n",
    "* *Referencias:*\n",
    "    * *http://www.nltk.org/*\n",
    "    * *http://www.python.org/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb",
   "metadata": {},
   "source": [
    "### a)Procesamiento del corpus cess_esp anotado con información morfosintáctica.\n",
    "\n",
    "* Dividir el corpus en dos partes: training (el 90% de las primeras frases) y de test (el 10% restante)\n",
    "* Reducir el conjunto de etiquetas morfosintácticas del corpus (289) a un conjunto reducido(67). Para ello, considerar las etiquetas de longitud =2 salvo los verbos (v) y los signos de puntuación (F) que pueden ser de tres. También pueden existir etiquetas de longitud =1. Eliminar también las tuplas vacias, por ejemplo: (u'*0*', u'sn'), son tuplas que el primer elemento tiene el valor '*0*'.\n",
    "\n",
    ">Nota: para entender el significado de las etiquetas se puede consultar el siguiente enlace: https://freeling-user-manual.readthedocs.io/en/latest/tagsets/tagset-es/\n",
    "\n",
    "Ejemplo de lo que se pide:\n",
    "* original\n",
    "```\n",
    "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n",
    "```\n",
    "* nuevo\n",
    "```\n",
    "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'fpa'), ('EDF', 'np'), ('-Fpt-', 'fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'fc'), ('jueves', 'w'), (',', 'fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'fpa'), ('EAA', 'np'), ('-Fpt-', 'fpt'), (',', 'fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vmn'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'z'), ('megavatios', 'nc'), ('.', 'fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vmi'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'fc'), ('prevé', 'vmm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'sp'), ('funcionar', 'vmn'), ('en', 'sp'), ('mayo_del_2002', 'w'), ('.', 'fp')]]\n",
    "```\n",
    "* opcional:\n",
    "    * número de frases: 6030\n",
    "    * número de palabras: 192686\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargar el corpus\n",
    "#1. ejecutar esta linea\n",
    "nltk.download()\n",
    "#2. elegir la opción d) Download\n",
    "#3. escribir identificador del corpus que deseamos, en nuestro caso 'cess_esp', 'punkt'... o bien 'all'\n",
    "#4. q) quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta linea carga el corpus en castellano, pero podemos hacerlo en ingles o catalan si os apetece\n",
    "from nltk.corpus import cess_esp\n",
    "corpus_sentences=cess_esp.tagged_sents()\n",
    "\n",
    "#opcional: calculamos el número de sentencias y palabras del corpus y los mostramos.\n",
    "\n",
    "#mostramos las 3 primeras frases del corpus (como está originalmente en el enunciado)\n",
    "\n",
    "#Escribir el corpus en un fichero\n",
    "\n",
    "#Leer el corpus de un fichero y guardalo en una lista\n",
    "\n",
    "#Definimos una funcion auxiliar (getLabel) que a partir de una etiqueta, la reduzca a su nueva versión siguiendo las instrucciones del enunciado\n",
    "\n",
    "#Definimos un array retic. A continuación leeremos todo el corpus, para cada etiqueta la procesaremos con getLabel y la guardaremos en retic.\n",
    "\n",
    "#mostramos las 3 primeras frases del corpus con las etiquetas reducidas (como muestra el enunciado)\n",
    "print(retic[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dee72f",
   "metadata": {},
   "source": [
    "### b) Uso de etiquetadores morfosintácticos (hmm o tnt).\n",
    "* Entrenar los etiquetadores con la partición de train previamente construida mostrar la precisión:\n",
    "\n",
    "```\n",
    "precisión hmm: 0.8784427571832664\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos la parte de corpus de entramiento (train 90%) y la parte de corpus de test (test 10%)\n",
    "\n",
    "#importamos el etiquetador hmm o tnt, lo entrenamos y mostramos su precisión (accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bae1bb",
   "metadata": {},
   "source": [
    "### c) Etiquetar con dicho modelo el conjunto de test construido\n",
    "* Evaluar las prestaciones sobre el conjunto de test\n",
    "* Hacer una evaluación de las prestaciones de etiquetado usando todo el corpus (10-fold cross validation).\n",
    "\n",
    "```\n",
    "Media de la precisión de los 10 KFolds:  0.9580362988365326\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63aade-6345-48f4-b559-d78f275ee306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos scikit-learn y mostramos la versión para comprobar que todo funcione bien.\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be17685-3072-4bc9-821d-0115b69f9713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Montamos el kfold de 10 splits sin shuffle y sin random_state\n",
    "#Para cada KFold guardamos su accuracy, y finalmente mostramos la media de los 10.\n",
    "from sklearn.model_selection import KFold \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0",
   "metadata": {},
   "source": [
    "### d) Tokenizar una frase y etiquetarla con el modelo entrenado previamente\n",
    "* Usar word_tokenize y tag del modelo usado (tnt, hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fab5ad-d2c8-4672-8453-f11d0739d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar el tokenizador de nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b71a91-6d42-4673-ba93-face2dddef5a",
   "metadata": {},
   "source": [
    "### e) De manera opcional puedes probar a cambiar el idioma, el corpus y ver si afecta mucho a la precisión de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974",
   "metadata": {},
   "source": [
    "### f) Entrega este notebook completado (asegurate que funciona correctamente, y renombralo añadiendo tu nombre y apellidos al final) en la tarea de AULES de la unidad 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
