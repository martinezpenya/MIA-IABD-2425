{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65e52c90c0c5ff06",
      "metadata": {
        "collapsed": false,
        "id": "65e52c90c0c5ff06"
      },
      "source": [
        "# Análisis de sentimientos\n",
        "\n",
        "En esta sección se realiza un análisis de sentimiento de tweets, como un ejemplo del uso de modelos de lenguaje previamente entrenado. En este caso, se utiliza el modelo [Distilbert](https://arxiv.org/abs/1910.01108) para el análisis de sentimientos. Este modelo es una versión más ligera del modelo. [BERT](https://arxiv.org/abs/1810.04805), que es un modelo de lenguaje previo a la entrada que se ha utilizado con muy buenos resultados en diferentes tareas de procesamiento del lenguaje natural, como [Análisis de sentimientos](https://arxiv.org/abs/1905.05583), [Clasificación de texto](https://arxiv.org/abs/1904.09077) o [Extracción de información](https://arxiv.org/abs/1906.05237).\n",
        "\n",
        "En este caso, se utiliza el modelo previamente entrenado para el análisis de sentimientos en inglés."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9012845d4dfa4e1f",
      "metadata": {
        "collapsed": false,
        "id": "9012845d4dfa4e1f"
      },
      "source": [
        "## Carga del conjunto de datos`\n",
        "\n",
        "Usaremos la librería [datasets](https://huggingface.co/docs/datasets/) Para cargar el `dataset` de los tweets. Esta La librería te permite cargar `datasets` de diferentes fuentes como [Hugging Face Hub](https://huggingface.co/datasets), [Amazon AWS](https://docs.aws.amazon.com/es_es/marketplace/latest/userguide/datasets.html) o [Google Cloud](https://cloud.google.com/ai-platform/training/docs/datasets). En este caso, cargaremos el `dataset` de tuits desde [Hugging Face Hub](https://huggingface.co/datasets/dair-ai/emotion).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d2a676e1e94a413c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:36:46.715988Z",
          "start_time": "2024-01-20T18:36:28.346946Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2a676e1e94a413c",
        "outputId": "a088a499-6497-4286-8287-507a05dc37d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Instalamos las librerias que vamos a usar\n",
        "\n",
        "%pip install transformers datasets evaluate accelerate keras scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "47ff17e0f41702d2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:36:48.675124Z",
          "start_time": "2024-01-20T18:36:46.721737Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47ff17e0f41702d2",
        "outputId": "9b9159cc-c1de-4ff4-d510-7042a75594f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'i didnt feel humiliated', 'label': 0}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "# Cargamos el Dataset\n",
        "dataset = datasets.load_dataset('dair-ai/emotion')\n",
        "\n",
        "# Mostramos los datos de ejemplo\n",
        "\n",
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557e71e114291a62",
      "metadata": {
        "collapsed": false,
        "id": "557e71e114291a62"
      },
      "source": [
        "Podemos ver que cada registro del `dataset` Contiene el texto del tweet y el sentimiento asociado. En este caso, el sentimiento está codificado con un entero entre 0 y 5, donde 0 corresponde a la tristeza, 1 a Alegria, 2 para amor, 3 a la ira, 4 para miedo y 5 para sorpresa.\n",
        "\n",
        "## Preparación del `dataset`\n",
        "\n",
        "En este caso, el `dataset` Ya está dividido en conjuntos de entrenamiento, prueba y validación. El siguiente paso es preparar el `dataset` para el entrenamiento modelo. En este caso, el modelo que utilizaremos es el modelo [BERT](https://arxiv.org/abs/1810.04805). Este modelo requiere que el texto sea tokenizado y los tokens estén codificados con sus identificadores numéricos correspondientes. Para hacer esto, utilizaremos un tokenizador DistilBERT previamente entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "43664c9255d80244",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:02.332329Z",
          "start_time": "2024-01-20T18:36:48.669963Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43664c9255d80244",
        "outputId": "dc760fcb-b200-47b7-a468-cef33216f593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 4429, 7623, 2003, 21746, 2023, 2095, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importamos el tokenizador de DistilBERT\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Cargamos el tokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Mostramos un ejemplo de tokenización\n",
        "tokenizer('FC Barcelona is fucked this year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "62e882459e05c211",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:02.399604Z",
          "start_time": "2024-01-20T18:37:02.344616Z"
        },
        "id": "62e882459e05c211"
      },
      "outputs": [],
      "source": [
        "# Definimos una función para preprocesar el texto.\n",
        "# Truncamos los textos para asegurarnos de que no excedan el máximo tamaño de entrada deDistilBert\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6939f908",
      "metadata": {
        "id": "6939f908"
      },
      "source": [
        "PAplicar la tokenización, usaremos la función `map` de `datasets`. Esta función permite aplicar una función a cada registro del `dataset`. En este caso, la función que aplicaremos es la función `tokenize` que hemos definido anteriormente. Nosotros también usaremos `batched=True` para indicar que la función se aplicará a todo `dataset` en bloques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "abb8dbbf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:02.473555Z",
          "start_time": "2024-01-20T18:37:02.388362Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e1bdf5ba61b2454580ad019b677df7f5",
            "f518e7a23c6449dba2dcdf1296aad71b",
            "308ece619ea241e89214f5b2865ed365",
            "0c0d34fd6bbe466ba2756c8d13d1c51a",
            "9aaff47a7d7e4729b755b773fb713b14",
            "0b64e885b9d345de8a3f9e45a923e907",
            "70e7b39c079a49ca93d901e3f496ed58",
            "26e498db8a0844daa4c9776c0e9de7c7",
            "0d9c0d99fb5346f2b8f0376a49c2bfb8",
            "af9519da56ba4f95820934d921387aed",
            "71e3147e68eb489fb126fdcdf69017ba"
          ]
        },
        "id": "abb8dbbf",
        "outputId": "ef3497d0-b22e-4a83-eebe-2f94b53ccd6a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1bdf5ba61b2454580ad019b677df7f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dades_tokenitzades = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b99f697b",
      "metadata": {
        "id": "b99f697b"
      },
      "source": [
        "A continuación usaremos `DataCollatorWithPadding` para crear un `DataCollator`, cuál es el objeto responsable de crear los tensores de entrada del modelo.En este caso usaremos `DataCollatorWithPadding` para crear tensores de tamaño fijo, agregando relleno a tensores más cortos.Esto es necesario para procesar los tensores en bloques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b28c3a8c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:28.126150Z",
          "start_time": "2024-01-20T18:37:02.460181Z"
        },
        "id": "b28c3a8c"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d57ecb92b50a55",
      "metadata": {
        "collapsed": false,
        "id": "83d57ecb92b50a55"
      },
      "source": [
        "## Evaluación\n",
        "\n",
        "Para evaluar el modelo, debemos cargar el método que utilizaremos para la evaluación.En este caso usaremos la métrica `accuracy` del módulo `evaluate` de HuggingFace.\n",
        "\n",
        "También definiremos una función para calcular las métricas del modelo. Esta función se utilizará para evaluar el modelo después de cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "c0929086e5ae324c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T19:58:06.781547Z",
          "start_time": "2024-01-20T19:57:59.595298Z"
        },
        "id": "c0929086e5ae324c"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6fab449e7194baf4",
      "metadata": {
        "id": "6fab449e7194baf4"
      },
      "outputs": [],
      "source": [
        "# Definimos una función para calcular la precisión del modelo\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16e0cb7d",
      "metadata": {
        "id": "16e0cb7d"
      },
      "source": [
        "## Definición de etiquetas\n",
        "\n",
        "Antes de entrenar el modelo, debemos crear un diccionario que traduzca los identificadores numéricos del sentimiento a sus etiquetas correspondientes y viceversa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0e13ef53",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:28.171577Z",
          "start_time": "2024-01-20T18:37:28.127484Z"
        },
        "id": "0e13ef53"
      },
      "outputs": [],
      "source": [
        "id_a_etiqueta = {\n",
        "    0: \"SADNESS\",\n",
        "    1: \"JOY\",\n",
        "    2: \"LOVE\",\n",
        "    3: \"ANGER\",\n",
        "    4: \"FEAR\",\n",
        "    5: \"SUPRISE\"\n",
        "}\n",
        "\n",
        "etiqueta_a_id = {\n",
        "    \"SADNESS\": 0,\n",
        "    \"JOY\": 1,\n",
        "    \"LOVE\": 2,\n",
        "    \"ANGER\": 3,\n",
        "    \"FEAR\": 4,\n",
        "    \"SUPRISE\": 5\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a3ea65",
      "metadata": {
        "id": "b7a3ea65"
      },
      "source": [
        "## Ajuste fino del modelo\n",
        "\n",
        "El proceso de ajuste fino del modelo es entrenar el modelo con nuestro `dataset`. Esto permite que el modelo se adapte mejor a nuestros datos y mejore su rendimiento.\n",
        "\n",
        "Necesitamos definir la función de optimización, el tamaño de los bloques y el número de épocas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c7d98ea89c53f22c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:28.174233Z",
          "start_time": "2024-01-20T18:37:28.158899Z"
        },
        "id": "c7d98ea89c53f22c"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "56beb32346161153",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:37:28.457731Z",
          "start_time": "2024-01-20T18:37:28.180929Z"
        },
        "id": "56beb32346161153"
      },
      "outputs": [],
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "# Definim la funció d'optimització\n",
        "batches_per_epoch = len(dades_tokenitzades['train']) // BATCH_SIZE\n",
        "total_steps = batches_per_epoch * NUM_EPOCHS\n",
        "total_train_steps = int(total_steps * NUM_EPOCHS)\n",
        "optimizer, lr_schedule = create_optimizer(\n",
        "    init_lr=2e-5,\n",
        "    num_train_steps=total_train_steps,\n",
        "    num_warmup_steps=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465bd2419cf0512c",
      "metadata": {
        "collapsed": false,
        "id": "465bd2419cf0512c"
      },
      "source": [
        "Ahora podemos cargar el modelo previamente capacitado y hacer el ajuste fino. Usaremos `TFAutoModelForSequenceClassification` y agregaremos las etiquetas que hemos definido previamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "203a3c0bbad47268",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:38:09.224610Z",
          "start_time": "2024-01-20T18:37:28.469556Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "203a3c0bbad47268",
        "outputId": "32fdda39-a2da-4b94-f068-3d22ebf9a1f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=len(etiqueta_a_id),\n",
        "    id2label=id_a_etiqueta,\n",
        "    label2id=etiqueta_a_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980c3617f18337d6",
      "metadata": {
        "collapsed": false,
        "id": "980c3617f18337d6"
      },
      "source": [
        "Huggingface proporciona modelos de formato `pytorch` por defecto. Para usarlos con `tensorflow` debemos usar la función `prepare_tf_dataset` del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e8fe534226a949de",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:38:10.095379Z",
          "start_time": "2024-01-20T18:38:09.188113Z"
        },
        "id": "e8fe534226a949de"
      },
      "outputs": [],
      "source": [
        "tf_train_dataset = model.prepare_tf_dataset(\n",
        "    dades_tokenitzades['train'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "tf_val_dataset = model.prepare_tf_dataset(\n",
        "    dades_tokenitzades['validation'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d261a08f52ef31",
      "metadata": {
        "collapsed": false,
        "id": "f8d261a08f52ef31"
      },
      "source": [
        "Para usar la función de evaluación que hemos definido previamente, debemos usar un `KerasMetricCallback` de Huggingface.Esta devolución de llamada hará la función `compute_metrics` correr después de cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8b14c9a521c42839",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T20:01:54.578691Z",
          "start_time": "2024-01-20T20:01:53.518106Z"
        },
        "id": "8b14c9a521c42839"
      },
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458df332906f97fc",
      "metadata": {
        "collapsed": false,
        "id": "458df332906f97fc"
      },
      "source": [
        "Ahora podemos compilar y entrenar el modelo, utilizando el `optimizer` y la devolución de llamada que hemos definido previamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d692f7b28c062d1c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-20T18:52:09.845966Z",
          "start_time": "2024-01-20T18:41:22.018058Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d692f7b28c062d1c",
        "outputId": "af8e6290-b631-47f8-debf-08f69bd34bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "FailedPreconditionError",
          "evalue": "Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_103 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-31-bb7ebd35e914>\", line 2, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\", line 1709, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 623, in minimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1309, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 731, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1339, in _internal_apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1431, in _distributed_apply_gradients_fn\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1426, in apply_grad_to_update_var\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_103}}]] [Op:__inference_train_function_32486]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bb7ebd35e914>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_val_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_103 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 250, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 748, in __init__\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-31-bb7ebd35e914>\", line 2, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\", line 1229, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_tf_utils.py\", line 1709, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 623, in minimize\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1309, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 731, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1339, in _internal_apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1431, in _distributed_apply_gradients_fn\n\n  File \"/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/optimizer.py\", line 1426, in apply_grad_to_update_var\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_103}}]] [Op:__inference_train_function_32486]"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=optimizer)\n",
        "model.fit(tf_train_dataset, epochs=NUM_EPOCHS, validation_data=tf_val_dataset, callbacks=[metric_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ONNQFTY5qCTj",
      "metadata": {
        "id": "ONNQFTY5qCTj"
      },
      "source": [
        "## Inferencia\n",
        "\n",
        "Para influir en el modelo, crearemos una tubería Huggingface. Esta tubería utilizará el modelo y el tokenizador que importamos anteriormente.\n",
        "\n",
        "Luego usaremos la tubería para hacer una inferencia con un texto de ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cRR9pIOThniA",
      "metadata": {
        "id": "cRR9pIOThniA"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "print(classifier(\"FC Barcelona is fucked this year\"))\n",
        "print(classifier(\"I'm not going to watch soccer again\"))\n",
        "print(classifier(\"Real Madrid is not going to treble this year. I'm relieved!\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b64e885b9d345de8a3f9e45a923e907": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c0d34fd6bbe466ba2756c8d13d1c51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9519da56ba4f95820934d921387aed",
            "placeholder": "​",
            "style": "IPY_MODEL_71e3147e68eb489fb126fdcdf69017ba",
            "value": " 2000/2000 [00:00&lt;00:00, 6052.93 examples/s]"
          }
        },
        "0d9c0d99fb5346f2b8f0376a49c2bfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26e498db8a0844daa4c9776c0e9de7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308ece619ea241e89214f5b2865ed365": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e498db8a0844daa4c9776c0e9de7c7",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d9c0d99fb5346f2b8f0376a49c2bfb8",
            "value": 2000
          }
        },
        "70e7b39c079a49ca93d901e3f496ed58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71e3147e68eb489fb126fdcdf69017ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aaff47a7d7e4729b755b773fb713b14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9519da56ba4f95820934d921387aed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bdf5ba61b2454580ad019b677df7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f518e7a23c6449dba2dcdf1296aad71b",
              "IPY_MODEL_308ece619ea241e89214f5b2865ed365",
              "IPY_MODEL_0c0d34fd6bbe466ba2756c8d13d1c51a"
            ],
            "layout": "IPY_MODEL_9aaff47a7d7e4729b755b773fb713b14"
          }
        },
        "f518e7a23c6449dba2dcdf1296aad71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b64e885b9d345de8a3f9e45a923e907",
            "placeholder": "​",
            "style": "IPY_MODEL_70e7b39c079a49ca93d901e3f496ed58",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
